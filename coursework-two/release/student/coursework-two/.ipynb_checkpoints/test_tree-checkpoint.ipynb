{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    \"\"\"Tree class.\n",
    "    \n",
    "    (You don't need to add any methods or fields here but feel\n",
    "    free to if you like. Our tests will only reference the fields\n",
    "    defined in the constructor below, so be sure to set these\n",
    "    correctly.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, left, right, parent, cutoff_id, cutoff_val, prediction):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent\n",
    "        self.cutoff_id = cutoff_id\n",
    "        self.cutoff_val = cutoff_val\n",
    "        self.prediction = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((281, 34), (281,), (70, 34), (70,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pylab import *\n",
    "from numpy.matlib import repmat\n",
    "import sys\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "sys.path.append('')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "%matplotlib notebook\n",
    "\n",
    "# DO NOT CHANGE: directory structure hack for grading\n",
    "file_loc = ''\n",
    "for path, subdirs, files in os.walk('../../../'):\n",
    "    if 'decision-tree-data' in subdirs:\n",
    "        file_loc = path + '/decision-tree-data/'\n",
    "        break\n",
    "\n",
    "\n",
    "# load in some binary test data (labels are -1, +1)\n",
    "data = loadmat(file_loc + \"ion.mat\")\n",
    "xTrIon  = data['xTr'].T\n",
    "yTrIon  = data['yTr'].flatten()\n",
    "xTeIon  = data['xTe'].T\n",
    "yTeIon  = data['yTe'].flatten()\n",
    "\n",
    "xTrIon.shape, yTrIon.shape, xTeIon.shape, yTeIon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spiraldata(N=300):\n",
    "    r = np.linspace(1,2*np.pi,N)\n",
    "    xTr1 = np.array([np.sin(2.*r)*r, np.cos(2*r)*r]).T\n",
    "    xTr2 = np.array([np.sin(2.*r+np.pi)*r, np.cos(2*r+np.pi)*r]).T\n",
    "    xTr = np.concatenate([xTr1, xTr2], axis=0)\n",
    "    yTr = np.concatenate([np.ones(N), -1 * np.ones(N)])\n",
    "    xTr = xTr + np.random.randn(xTr.shape[0], xTr.shape[1])*0.2\n",
    "    \n",
    "    xTe = xTr[::2,:]\n",
    "    yTe = yTr[::2]\n",
    "    xTr = xTr[1::2,:]\n",
    "    yTr = yTr[1::2]\n",
    "    \n",
    "    return xTr,yTr,xTe,yTe\n",
    "\n",
    "xTrSpiral,yTrSpiral,xTeSpiral,yTeSpiral=spiraldata(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 2), (150,), (150, 2), (150,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrSpiral.shape, yTrSpiral.shape, xTeSpiral.shape, yTeSpiral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 3), (8,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor1 = np.array([[1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                 [1, 1, 0, 0, 1, 1, 0, 0],\n",
    "                 [1, 0, 1, 0, 1, 0, 1, 0]]).T\n",
    "yor1 = np.array( [1, 0, 0, 1, 0, 1, 1, 0])\n",
    "#b = np.isclose(sqsplit(xor1,yor1)[2], .25)\n",
    "xor1.shape, yor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqsplit(xTr,yTr,weights=[]):\n",
    "    \"\"\"Finds the best feature, cut value, and loss value.\n",
    "    \n",
    "    Input:\n",
    "        xTr:     n x d matrix of data points\n",
    "        yTr:     n-dimensional vector of labels\n",
    "        weights: n-dimensional weight vector for data points\n",
    "    \n",
    "    Output:\n",
    "        feature:  index of the best cut's feature\n",
    "        cut:      cut-value of the best cut\n",
    "        bestloss: loss of the best cut\n",
    "    \"\"\"\n",
    "    N,D = xTr.shape\n",
    "    assert D > 0 # must have at least one dimension\n",
    "    assert N > 1 # must have at least two samples\n",
    "    if weights == []: # if no weights are passed on, assign uniform weights\n",
    "        weights = np.ones(N)\n",
    "    weights = weights/sum(weights) # Weights need to sum to one (we just normalize them)\n",
    "    bestloss = np.inf\n",
    "    feature = np.inf\n",
    "    cut = np.inf\n",
    "    \n",
    "    # Split a training set based on a feature and a cut\n",
    "    losses = []\n",
    "    y = yTr.reshape((N,1))\n",
    "    data = np.hstack((xTr,y))\n",
    "    for j in range(D):\n",
    "        k = 0\n",
    "        k_arr = []\n",
    "        x = sorted(xTr[:,j]) \n",
    "        for i in range(N-1):\n",
    "            k_new = (x[i]+x[i+1])/2\n",
    "            if k_new != k:\n",
    "                k = k_new\n",
    "                k_arr.append(k)\n",
    "         \n",
    "        for k in k_arr:\n",
    "            datal,datar = [],[]\n",
    "            wl,wr = [],[] \n",
    "            for i in range(N):\n",
    "                if data[i,j]<=k:\n",
    "                    datal.append(data[i,:])\n",
    "                    wl.append(weights[i])\n",
    "                else:\n",
    "                    datar.append(data[i,:])\n",
    "                    wr.append(weights[i])\n",
    "             # calculate loss and update through splits\n",
    "            dataL,dataR = np.array(datal),np.array(datar)\n",
    "            wL,wR = np.array(wl),np.array(wr)\n",
    "\n",
    "            yL = dataL[:,-1]\n",
    "            yR = dataR[:,-1]\n",
    "            \n",
    "            T_L,T_R = 1/sum(wL)*np.dot(wL,yL),1/sum(wR)*np.dot(wR,yR)\n",
    "            current_loss = np.dot(wL,(yL-T_L)**2)+ np.dot(wR,(yR-T_R)**2)\n",
    "\n",
    "            if current_loss <= bestloss:\n",
    "                bestloss = current_loss\n",
    "                cut = k\n",
    "                feature = j\n",
    "\n",
    "    return feature,cut,bestloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 5.6792378425598145 seconds\n",
      "It should split on feature 2 on value 0.304\n",
      "Split on feature 2 on value: 0.304\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "fid,cut,loss = sqsplit(xTrIon,yTrIon)\n",
    "t1 = time.time()\n",
    "print('elapsed time:',t1-t0,'seconds')\n",
    "print(\"It should split on feature 2 on value 0.304\")\n",
    "print(\"Split on feature %i on value: %2.3f\" % (fid,cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example test\n",
    "xor1 = np.array([[1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                 [1, 1, 0, 0, 1, 1, 0, 0],\n",
    "                 [1, 0, 1, 0, 1, 0, 1, 0]]).T\n",
    "yor1 = np.array( [1, 0, 0, 1, 0, 1, 1, 0])\n",
    "# b = np.isclose(sqsplit(xor1,yor1)[2], .25)\n",
    "# print('Function sqsplit correctly calculates bestloss on xor1/yor1 example: ' + str(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D = xor1.shape\n",
    "losses = []\n",
    "y = yor1.reshape((N,1))\n",
    "data = np.hstack((xTr,y))\n",
    "weights = weights/sum(weights)\n",
    "for j in range(D):\n",
    "    k = 0\n",
    "    k_arr = []\n",
    "    x = sorted(xor1[:,j]) \n",
    "    for i in range(N-1):\n",
    "        k_new = (x[i]+x[i+1])/2\n",
    "        if k_new != k:\n",
    "            k = k_new\n",
    "            k_arr.append(k)\n",
    "\n",
    "    for k in k_arr:\n",
    "        datal,datar = [],[]\n",
    "        wl,wr = [],[] \n",
    "        for i in range(N):\n",
    "            if data[i,j]<=k:\n",
    "                datal.append(data[i,:])\n",
    "                wl.append(weights[i])\n",
    "            else:\n",
    "                datar.append(data[i,:])\n",
    "                wr.append(weights[i])\n",
    "         # calculate loss and update through splits\n",
    "        dataL,dataR = np.array(datal),np.array(datar)\n",
    "        wL,wR = np.array(wl),np.array(wr)\n",
    "\n",
    "        yL = dataL[:,-1]\n",
    "        yR = dataR[:,-1]\n",
    "\n",
    "        T_L,T_R = 1/sum(wL)*np.dot(wL,yL),1/sum(wR)*np.dot(wR,yR)\n",
    "        current_loss = np.dot(wL,(yL-T_L)**2)+ np.dot(wR,(yR-T_R)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart(xTr,yTr,maxdepth=np.inf,weights=None):\n",
    "    \"\"\"Builds a CART tree.\n",
    "    \n",
    "    The maximum tree depth is defined by \"maxdepth\" (maxdepth=2 means one split).\n",
    "    Each example can be weighted with \"weights\".\n",
    "\n",
    "    Args:\n",
    "        xTr:      n x d matrix of data\n",
    "        yTr:      n-dimensional vector\n",
    "        maxdepth: maximum tree depth\n",
    "        weights:  n-dimensional weight vector for data points\n",
    "\n",
    "    Returns:\n",
    "        tree: root of decision tree\n",
    "    \"\"\"\n",
    "    n,d = xTr.shape\n",
    "    if weights is None:\n",
    "        w = np.ones(n) / float(n)\n",
    "    else:\n",
    "        w = weights\n",
    "    \n",
    "    # get root node value\n",
    "    feature,cut,_ = sqsplit(xTr,yTr,w)\n",
    "    y = yTr.reshape((n,1))\n",
    "    data = np.hstack((xTr,y))\n",
    "    datal,datar = [],[]\n",
    "    for i in range(n):\n",
    "        if data[i,j]<=cut:\n",
    "            datal.append(data[i,:])\n",
    "        else:\n",
    "            datar.append(data[i,:])\n",
    "            \n",
    "    dataL,dataR = np.array(datal),np.array(datar)\n",
    "    \n",
    "    node = TreeNode(dataL,dataR,None,feature,cut,0)\n",
    "    \n",
    "    \n",
    "    node.parent = cart # return one tree node\n",
    "    \n",
    "    # process left child\n",
    "    if len(node.left)<= 1:\n",
    "        outcomes = node.left[:,-1]\n",
    "        counts = np.bincount(outcomes)\n",
    "        prediction = np.argmax(counts)\n",
    "    else:\n",
    "        d1 = node.left.shape[1]\n",
    "        xTr = node.left[:,d1-1]\n",
    "        yTr = node.left[:,-1]\n",
    "        cart(xTr,yTr,maxdepth=np.inf,w)\n",
    "        \n",
    "    # process right child    \n",
    "    if len(node.right)<= 1:\n",
    "        outcomes = node.left[:,-1]\n",
    "        counts = np.bincount(outcomes)\n",
    "        prediction = np.argmax(counts)\n",
    "    else:\n",
    "        d1 = node.right.shape[1]\n",
    "        xTr = node.right[:,d1-1]\n",
    "        yTr = node.right[:,-1]\n",
    "        cart(xTr,yTr,maxdepth=np.inf,w)\n",
    "        \n",
    "        \n",
    "    if depth >= maxdepth:\n",
    "        outcomesl = l[:,-1]\n",
    "        countsl = np.bincount(outcomesl)\n",
    "        predictionl = np.argmax(countsl)\n",
    "        \n",
    "        outcomesr = r[:,-1]\n",
    "        countsr = np.bincount(outcomesr)\n",
    "        predictionr = np.argmax(countsr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Apple(object):\n",
    "    def __init__(self, color,length):\n",
    "        self.color=color\n",
    "        self.length=length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest(xTr, yTr, m, maxdepth=np.inf):\n",
    "    \"\"\"Creates a random forest.\n",
    "    \n",
    "    Input:\n",
    "        xTr:      n x d matrix of data points\n",
    "        yTr:      n-dimensional vector of labels\n",
    "        m:        number of trees in the forest\n",
    "        maxdepth: maximum depth of tree\n",
    "        \n",
    "    Output:\n",
    "        trees: list of TreeNode decision trees of length m\n",
    "    \"\"\"\n",
    "    \n",
    "    n, d = xTr.shape\n",
    "    trees = []\n",
    "    \n",
    "    # create m random sample\n",
    "    y = yTr.reshape((n,1))\n",
    "    data = np.hstack((xTr,y))\n",
    "    \n",
    "    m_samples=[]\n",
    "    for i in range(m):\n",
    "        D_i = []\n",
    "        while len(D_I) < n:\n",
    "            index = np.random.choice(n,1,True)\n",
    "            D_i.append(data[index])\n",
    "        m_samples.append(D_i)\n",
    "            \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1,2,3],\n",
    "                [2,4,5],\n",
    "                [2,2,2],\n",
    "                [3,4,5],\n",
    "                [4,5,6],\n",
    "                [2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = data[:,-1]\n",
    "counts = np.bincount(outcomes)\n",
    "prediction = np.argmax(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menu (this assumes no duplicate keys)\n",
      "insert <data> at root\n",
      "insert <data> left of <data>\n",
      "insert <data> right of <data>\n",
      "quit\n",
      "inorder traversal of binary tree: \n",
      "What would you like to do? quit\n"
     ]
    }
   ],
   "source": [
    "class BinaryTree:\n",
    "    def __init__(self, key=None):\n",
    "        self.key = key\n",
    "        self.left = None\n",
    "        self.right = None\n",
    " \n",
    "    def set_root(self, key):\n",
    "        self.key = key\n",
    " \n",
    "    def inorder(self):\n",
    "        if self.left is not None:\n",
    "            self.left.inorder()\n",
    "        print(self.key, end=' ')\n",
    "        if self.right is not None:\n",
    "            self.right.inorder()\n",
    " \n",
    "    def insert_left(self, new_node):\n",
    "        self.left = new_node\n",
    " \n",
    "    def insert_right(self, new_node):\n",
    "        self.right = new_node\n",
    " \n",
    "    def search(self, key):\n",
    "        if self.key == key:\n",
    "            return self\n",
    "        if self.left is not None:\n",
    "            temp =  self.left.search(key)\n",
    "            if temp is not None:\n",
    "                return temp\n",
    "        if self.right is not None:\n",
    "            temp =  self.right.search(key)\n",
    "            return temp\n",
    "        return None\n",
    " \n",
    " \n",
    "btree = None\n",
    " \n",
    "print('Menu (this assumes no duplicate keys)')\n",
    "print('insert <data> at root')\n",
    "print('insert <data> left of <data>')\n",
    "print('insert <data> right of <data>')\n",
    "print('quit')\n",
    " \n",
    "while True:\n",
    "    print('inorder traversal of binary tree: ', end='')\n",
    "    if btree is not None:\n",
    "        btree.inorder()\n",
    "    print()\n",
    " \n",
    "    do = input('What would you like to do? ').split()\n",
    " \n",
    "    operation = do[0].strip().lower()\n",
    "    if operation == 'insert':\n",
    "        data = int(do[1])\n",
    "        new_node = BinaryTree(data)\n",
    "        suboperation = do[2].strip().lower() \n",
    "        if suboperation == 'at':\n",
    "                btree = new_node\n",
    "        else:\n",
    "            position = do[4].strip().lower()\n",
    "            key = int(position)\n",
    "            ref_node = None\n",
    "            if btree is not None:\n",
    "                ref_node = btree.search(key)\n",
    "            if ref_node is None:\n",
    "                print('No such key.')\n",
    "                continue\n",
    "            if suboperation == 'left':\n",
    "                ref_node.insert_left(new_node)\n",
    "            elif suboperation == 'right':\n",
    "                ref_node.insert_right(new_node)\n",
    " \n",
    "    elif operation == 'quit':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
